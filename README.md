# LLM-for-Mental-Health-Research

A curated paper list of mental health research using large language models (LLMs) and multimodal large language models (MLLMs).

## Explore

## AI Safety for Human Mental Health

### Satety of Generation AI
- ![2023.10](https://img.shields.io/badge/2023.10-blue) ![JCP](https://img.shields.io/badge/JCP-green) [Chatbots and mental health: Insights into the safety of generative AI](https://myscp.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jcpy.1393)


### Ethical Evaluation
Evaluate LLMs for mental health applications ethically.

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![LDH](https://img.shields.io/badge/LDH-green) [Ethical Evaluation of Large Language Models for Mental Health Applications](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00255-3/fulltext)

- ![2024.11](https://img.shields.io/badge/2024.11-blue) ![EMNLP](https://img.shields.io/badge/EMNLP-red) [Can AI Relate: Testing Large Language Model Response for Mental Health Support](https://aclanthology.org/2024.findings-emnlp.120/) [[code]](https://github.com/skgabriel/mh-eval)

- ![2024.10](https://img.shields.io/badge/2024.10-blue) ![FPsy](https://img.shields.io/badge/FPsy-green) [Can AI replace psychotherapists? Exploring the future of mental health care](https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2024.1444382/full)


- ![2021.11](https://img.shields.io/badge/2021.11-blue) ![EMNLP](https://img.shields.io/badge/EMNLP-red) [A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support](https://par.nsf.gov/servlets/purl/10293300)

- ![2017.04](https://img.shields.io/badge/2017.04-blue) ![EthNLP](https://img.shields.io/badge/EthNLP-red) [Ethical Research Protocols for Social Media Health Research](https://aclanthology.org/W17-1612/)



## Emotion Detection

- ![2024.08](https://img.shields.io/badge/2024.08-blue) ![KDD](https://img.shields.io/badge/KDD-red) [Emollms: A series of emotional large language models and annotation tools for comprehensive affective analysis](https://dl.acm.org/doi/abs/10.1145/3989613.4084128)




## Methods for Suicide Risk Assessment and Detection

### Surveys
- ![2025.05](https://img.shields.io/badge/2025.05-blue) ![JMIR](https://img.shields.io/badge/JMIR-green) [A survey of large language models for mental health applications](https://www.jmir.org/2025/1/e69284/)

- ![2025.04](https://img.shields.io/badge/2025.04-blue)  ![NPJDM](https://img.shields.io/badge/NPJDM-green) [A scoping review of large language models for generative tasks in mental health care](https://www.nature.com/articles/s41746-025-01611-4.pdf)


- ![2024.06](https://img.shields.io/badge/2024.06-blue) ![JTS](https://img.shields.io/badge/JTS-green) [An Overview of Diagnostics and Therapeutics Using Large
Language Models](https://onlinelibrary.wiley.com/doi/pdf/10.1002/jts.23082?casa_token=GlVb_7RF7kIAAAAA%3AFvnWC12H0qtmmguh3EEl10RcoATL4W_LnUi4nAgdkXO-HC3lCSeljxLHPOmcJfyaxnRnPn3eXxBDdQ)


### LLM as an Agent for Mental Health
LLMs as agents with access to external tools like clinical databases, risk assessment frameworks, etc.

- ![2025.05](https://img.shields.io/badge/2025.05-blue) ![Nature](https://img.shields.io/badge/Nature-green) [Leveraging large language models to assist philosophical counseling: prospective techniques, value, and challenges](https://www.nature.com/articles/s41599-025-04657-7)

- ![2024.05](https://img.shields.io/badge/2024.05-blue) ![IMWUT](https://img.shields.io/badge/IMWUT-red) [Talk2care: An llm-based voice assistant for communication between healthcare providers and older adults](https://dl.acm.org/doi/abs/10.1145/3659625)

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![arxiv](https://img.shields.io/badge/arxiv-yellow) [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org/pdf/2504.09689) [[code]](https://github.com/1akaman/EmoAgent)

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![CHI](https://img.shields.io/badge/CHI-red) [ASHABot: An LLM-Powered Chatbot to Support the Informational Needs of Community Health Workers](https://dl.acm.org/doi/full/10.1145/3706598.3713680)

- ![2024.05](https://img.shields.io/badge/2024.05-blue) ![WWW](https://img.shields.io/badge/WWW-red) [MentaLLaMA: interpretable mental health analysis on social media with large language models](https://dl.acm.org/doi/abs/10.1145/3589334.3648137) [[code]](https://github.com/SteveKGYang/MentalLLaMA)

- ![2024.03](https://img.shields.io/badge/2024.03-blue) ![IMWUT](https://img.shields.io/badge/IMWUT-red) [Mental-LLM: Leveraging large language models for mental health prediction via online text data](https://dl.acm.org/doi/abs/10.1145/3643540)

- ![2023.07](https://img.shields.io/badge/2023.07-blue) ![AAAI](https://img.shields.io/badge/AAAI-red) [Increasing impact of mobile health programs: Saheli for maternal and child care](https://ojs.aaai.org/index.php/AAAI/article/view/26849)


### LLM as an Agent for Therapy

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![JMIR](https://img.shields.io/badge/JMIR-green) [Guideline-Incorporated Large Language Model-Driven Evaluation of Medical Records Using MedCheckLLM](https://formative.jmir.org/2025/1/e53335/)

- ![2024.07](https://img.shields.io/badge/2024.07-blue) ![JMIR](https://img.shields.io/badge/JMIR-green) [Exploring the efficacy of large language models in summarizing mental health counseling sessions: benchmark study](https://mental.jmir.org/2024/1/e57306/)




### Suside Detection Methods
- ![2025.05](https://img.shields.io/badge/2025.05-blue) ![arxiv](https://img.shields.io/badge/arxiv-yellow) [Evidence-Driven Marker Extraction for Social Media Suicide Risk Detection](https://arxiv.org/abs/2502.18823)

- ![2021.09](https://img.shields.io/badge/2021.09-blue) ![ICANN](https://img.shields.io/badge/ICANN-red) [Deep learning for suicide and depression identification with unsupervised label correction](https://link.springer.com/chapter/10.1007/978-3-030-86383-8_35) [[code]](https://github.com/ayaanzhaque/SDCNL)


## Dataset
- ![2024.03](https://img.shields.io/badge/2024.03-blue) ![CLPsych](https://img.shields.io/badge/CLPsych-red) [Overview of the clpsych 2024 shared task: Leveraging large language models to identify evidence of suicidality risk in online posts](https://aclanthology.org/2024.clpsych-1.15/)

- ![2023.07](https://img.shields.io/badge/2023.07-blue) ![ACL](https://img.shields.io/badge/ACL-red) [An Annotated Dataset for Explainable Interpersonal Risk Factors of Mental Disturbance in Social Media Posts](https://aclanthology.org/2023.findings-acl.757/) [[code]](https://github.com/drmuskangarg/Irf)


- ![2023.05](https://img.shields.io/badge/2023.05-blue) ![arxiv](https://img.shields.io/badge/arxiv-yellow) [Multiwd: Multiple wellness dimensions in social media posts](https://www.techrxiv.org/doi/full/10.36227/techrxiv.22816586.v1) [[code]](https://github.com/drmuskangarg/MultiWD)

- ![2022.04](https://img.shields.io/badge/2022.04-blue) ![WWW](https://img.shields.io/badge/WWW-red) [Early identification of depression severity levels on reddit using ordinal classification](https://dl.acm.org/doi/abs/10.1145/3485447.3512128)

- ![2021.05](https://img.shields.io/badge/2021.05-blue) ![CHI](https://img.shields.io/badge/CHI-red) [Sad: A stress annotated dataset for recognizing everyday stressors in sms-like conversational systems](https://dl.acm.org/doi/10.1145/3411763.34517992) [[code]](https://github.com/PervasiveWellbeingTech/Stress-Annotated-Dataset-SAD)


- ![2019.11](https://img.shields.io/badge/2019.11-blue) ![LOUHI](https://img.shields.io/badge/LOUHI-red) [Dreaddit: A Reddit Dataset for Stress Analysis in Social Media](https://aclanthology.org/2024.clpsych-1.15/) [[code]](http://www.cs.columbia.edu/~eturcan/data)


- ![2019.06](https://img.shields.io/badge/2019.06-blue) ![CLPsych](https://img.shields.io/badge/CLPsych-red) [CLPsych 2019 shared task: Predicting the degree of suicide risk in Reddit posts](https://aclanthology.org/W19-3003/)

- ![2019.05](https://img.shields.io/badge/2019.05-blue) ![WWW](https://img.shields.io/badge/WWW-red) [Knowledge-aware assessment of severity of suicide risk for early intervention](https://dl.acm.org/doi/abs/10.1145/3308558.3313698) [[code]](https://zenodo.org/records/2667859)

- ![2018.10](https://img.shields.io/badge/2018.10-blue) ![EMNLP](https://img.shields.io/badge/EMNLP-red) [Identifying Depression on Reddit: The Effect of Training Data](https://aclanthology.org/W18-5903/) [[code]](https://github.com/Inusette/Identifying-depression)


- ![2018.06](https://img.shields.io/badge/2018.06-blue) ![CLPsych](https://img.shields.io/badge/CLPsych-red) [Expert, crowdsourced, and machine assessment of suicide risk via online postings](https://aclanthology.org/W18-5903/)

- ![2016.10](https://img.shields.io/badge/2016.10-blue) ![SLTB](https://img.shields.io/badge/SITB-green) [College students' responses to suicidal content on social networking sites: An examination using a simulated facebook newsfeed](https://onlinelibrary.wiley.com/doi/pdf/10.1111/sltb.12241)

- ![2016.08](https://img.shields.io/badge/2016.08-blue) ![CLEF](https://img.shields.io/badge/CLEF-red) [A test collection for research on depression and language use](https://link.springer.com/chapter/10.1007/978-3-319-44564-9_3)

- ![2008.06](https://img.shields.io/badge/2008.06-blue) ![AAAI](https://img.shields.io/badge/AAAI-red) [The psychology of word use in depression forums in English and in Spanish: Testing two text analytic approaches](https://ojs.aaai.org/index.php/ICWSM/article/view/18623)




## Evaluation Metrics
- [The PHQ‚Äê9: Validity of a Brief Depression Severity Measure](https://onlinelibrary.wiley.com/doi/pdf/10.1046/j.1525-1497.2001.016009606.x)

- [Measuring delusional ideation: the 21-item Peters et al. Delusions Inventory (PDI)](https://academic.oup.com/schizophreniabulletin/article-abstract/30/4/1005/1930847)

- [Measured using the Positive and Negative Syndrome Scale (PANSS)](https://academic.oup.com/schizophreniabulletin/article/13/2/261/1919795)

- [A technique for the Measurement of Attitudes (Likert Scale)](https://psycnet.apa.org/record/1933-01885-001)

- [Motivational Interviewing: Moving From Why to How with Autonomy Support (MITI)](https://link.springer.com/content/pdf/10.1186/1479-5868-9-19.pdf)

- [Columbia-suicide severity rating scale (C-SSRS)](https://doc.sc.gov/sites/doc/files/Documents/policy/BH-19-11AttachmentC.pdf)

- [The DSM-5: Classification and criteria changes](https://onlinelibrary.wiley.com/doi/full/10.1002/wps.20050)

- [The Beck Depression Inventory (BDI)](https://jamanetwork.com/journals/jamapsychiatry/article-abstract/487993)

- [Depressive disorder annotation (DDA)](https://aclanthology.org/W15-1211.pdf)


<!-- ### As a Decision Maker/Explainer

LLMs directly making assessments or providing explanations for suicide risk factors.

- ![2023.08](https://img.shields.io/badge/2023.08-blue) [Example Paper Title 5](https://example.com/paper5) [[paper]](https://example.com/paper5.pdf)
- ![2024.01](https://img.shields.io/badge/2024.01-blue) [Example Paper Title 6](https://example.com/paper6) [[paper]](https://example.com/paper6.pdf) -->
<!-- 
## Intervention and Support Systems







## About

This repository aims to track and organize research on the application of large language models in suicide prevention, risk assessment, and intervention. The papers are categorized based on how LLMs are utilized in this sensitive and important domain.

## Contributing

To contribute to this repository, please submit a pull request with your suggested additions. Ensure that papers are relevant to both suicide research and large language models.
