# LLM-for-Mental-Health-Research

A curated paper list of mental health research using large language models (LLMs) and multimodal large language models (MLLMs).

## Explore

## AI Safety for Human Mental Health

### Satety of Generation AI
- ![2023.10](https://img.shields.io/badge/2023.10-blue) ![JCP](https://img.shields.io/badge/JCP-green) [Chatbots and mental health: Insights into the safety of generative AI](https://myscp.onlinelibrary.wiley.com/doi/pdfdirect/10.1002/jcpy.1393)


### Ethical Evaluation
Evaluate LLMs for mental health applications ethically.

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![LDH](https://img.shields.io/badge/LDH-green) [Ethical Evaluation of Large Language Models for Mental Health Applications](https://www.thelancet.com/journals/landig/article/PIIS2589-7500(24)00255-3/fulltext)

- ![2024.11](https://img.shields.io/badge/2024.11-blue) ![EMNLP](https://img.shields.io/badge/EMNLP-red) [Can AI Relate: Testing Large Language Model Response for Mental Health Support](https://aclanthology.org/2024.findings-emnlp.120/) [[code]](https://github.com/skgabriel/mh-eval)

- ![2024.10](https://img.shields.io/badge/2024.10-blue) ![FPsy](https://img.shields.io/badge/FPsy-green) [Can AI replace psychotherapists? Exploring the future of mental health care](https://www.frontiersin.org/journals/psychiatry/articles/10.3389/fpsyt.2024.1444382/full)


- ![2021.11](https://img.shields.io/badge/2021.11-blue) ![EMNLP](https://img.shields.io/badge/EMNLP-red) [A Computational Approach to Understanding Empathy Expressed in Text-Based Mental Health Support](https://par.nsf.gov/servlets/purl/10293300)

- ![2017.04](https://img.shields.io/badge/2017.04-blue) ![EthNLP](https://img.shields.io/badge/EthNLP-red) [Ethical Research Protocols for Social Media Health Research](https://aclanthology.org/W17-1612/)





## Methods for Suicide Risk Assessment and Detection

### Surveys
- ![2025.05](https://img.shields.io/badge/2025.05-blue) ![JMIR](https://img.shields.io/badge/JMIR-green) [A survey of large language models for mental health applications](https://www.jmir.org/2025/1/e69284/)

- ![2025.04](https://img.shields.io/badge/2025.04-blue)  ![NPJDM](https://img.shields.io/badge/NPJDM-green) [A scoping review of large language models for generative tasks in mental health care](https://www.nature.com/articles/s41746-025-01611-4.pdf)


- ![2024.06](https://img.shields.io/badge/2024.06-blue) ![JTS](https://img.shields.io/badge/JTS-green) [An Overview of Diagnostics and Therapeutics Using Large
Language Models](https://onlinelibrary.wiley.com/doi/pdf/10.1002/jts.23082?casa_token=GlVb_7RF7kIAAAAA%3AFvnWC12H0qtmmguh3EEl10RcoATL4W_LnUi4nAgdkXO-HC3lCSeljxLHPOmcJfyaxnRnPn3eXxBDdQ)


### LLM as an Agent for Mental Health
LLMs as agents with access to external tools like clinical databases, risk assessment frameworks, etc.

- ![2025.05](https://img.shields.io/badge/2025.05-blue) ![Nature](https://img.shields.io/badge/Nature-green) [Leveraging large language models to assist philosophical counseling: prospective techniques, value, and challenges](https://www.nature.com/articles/s41599-025-04657-7)


- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![arxiv](https://img.shields.io/badge/arxiv-yellow) [EmoAgent: Assessing and Safeguarding Human-AI Interaction for Mental Health Safety](https://arxiv.org/pdf/2504.09689) [[code]](https://github.com/1akaman/EmoAgent)

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![CHI](https://img.shields.io/badge/CHI-red) [ASHABot: An LLM-Powered Chatbot to Support the Informational Needs of Community Health Workers](https://dl.acm.org/doi/full/10.1145/3706598.3713680)


- ![2024.05](https://img.shields.io/badge/2024.05-blue) ![WWW](https://img.shields.io/badge/WWW-red) [MentaLLaMA: interpretable mental health analysis on social media with large language models](https://dl.acm.org/doi/abs/10.1145/3589334.3648137)


- ![2023.07](https://img.shields.io/badge/2023.07-blue) ![AAAI](https://img.shields.io/badge/AAAI-red) [Increasing impact of mobile health programs: Saheli for maternal and child care](https://ojs.aaai.org/index.php/AAAI/article/view/26849)


### LLM as an Agent for Therapy

- ![2025.04](https://img.shields.io/badge/2025.04-blue) ![JMIR](https://img.shields.io/badge/JMIR-green) [Guideline-Incorporated Large Language Model-Driven Evaluation of Medical Records Using MedCheckLLM](https://formative.jmir.org/2025/1/e53335/)

- ![2024.07](https://img.shields.io/badge/2024.07-blue) ![JMIR](https://img.shields.io/badge/JMIR-green) [Exploring the efficacy of large language models in summarizing mental health counseling sessions: benchmark study](https://mental.jmir.org/2024/1/e57306/)




### Suside Detection Methods
- ![2025.05](https://img.shields.io/badge/2025.05-blue) ![arxiv](https://img.shields.io/badge/arxiv-yellow) [Evidence-Driven Marker Extraction for Social Media Suicide Risk Detection](https://arxiv.org/abs/2502.18823)





## Dataset
- ![2024.03](https://img.shields.io/badge/2024.03-blue) ![CLPsych](https://img.shields.io/badge/CLPsych-red) [Overview of the clpsych 2024 shared task: Leveraging large language models to identify evidence of suicidality risk in online posts](https://aclanthology.org/2024.clpsych-1.15/)

- ![2019.06](https://img.shields.io/badge/2019.06-blue) ![CLPsych](https://img.shields.io/badge/CLPsych-red) [CLPsych 2019 shared task: Predicting the degree of suicide risk in Reddit posts](https://aclanthology.org/W19-3003/)






## Evaluation Metrics
- [The PHQ‚Äê9: Validity of a Brief Depression Severity Measure](https://onlinelibrary.wiley.com/doi/pdf/10.1046/j.1525-1497.2001.016009606.x)

- [Measuring delusional ideation: the 21-item Peters et al. Delusions Inventory (PDI)](https://academic.oup.com/schizophreniabulletin/article-abstract/30/4/1005/1930847)

- [Measured using the Positive and Negative Syndrome Scale (PANSS)](https://academic.oup.com/schizophreniabulletin/article/13/2/261/1919795)

- [A technique for the Measurement of Attitudes (Likert Scale)](https://psycnet.apa.org/record/1933-01885-001)

- [Motivational Interviewing: Moving From Why to How with Autonomy Support (MITI)](https://link.springer.com/content/pdf/10.1186/1479-5868-9-19.pdf)

<!-- ### As a Decision Maker/Explainer

LLMs directly making assessments or providing explanations for suicide risk factors.

- ![2023.08](https://img.shields.io/badge/2023.08-blue) [Example Paper Title 5](https://example.com/paper5) [[paper]](https://example.com/paper5.pdf)
- ![2024.01](https://img.shields.io/badge/2024.01-blue) [Example Paper Title 6](https://example.com/paper6) [[paper]](https://example.com/paper6.pdf) -->
<!-- 
## Intervention and Support Systems







## About

This repository aims to track and organize research on the application of large language models in suicide prevention, risk assessment, and intervention. The papers are categorized based on how LLMs are utilized in this sensitive and important domain.

## Contributing

To contribute to this repository, please submit a pull request with your suggested additions. Ensure that papers are relevant to both suicide research and large language models.
